{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharan-pai-bmsce/ML-C3/blob/main/ID3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "data=pd.read_csv('/content/dataset-1.csv');\n",
        "\n",
        "attributes=[feat for feat in data]\n",
        "attributes.remove('answer')\n",
        "# print(features)\n",
        "class Node:\n",
        "  def __init__(self):\n",
        "    self.children=[];\n",
        "    self.isLeaf=False;\n",
        "    self.value=\"\";\n",
        "    self.pred=\"\";\n",
        "\n",
        "def main():\n",
        "  res=ID3(data,attributes)\n",
        "  printTree(res)\n",
        "\n",
        "def printTree(root: Node, depth=0):\n",
        "    for i in range(depth):\n",
        "        print(\"\\t\", end=\"\")\n",
        "    \n",
        "    print(root.value, end=\"\")\n",
        "    \n",
        "    if root.isLeaf:\n",
        "        print(\" ->\", root.pred)\n",
        "    \n",
        "    print()\n",
        "    \n",
        "    for child in root.children:\n",
        "        printTree(child, depth + 1)\n",
        "\n",
        "# This function creates the decision tree recursively\n",
        "def ID3(data_set,attributes):\n",
        "  root=Node()\n",
        "  max_gain=0.0;\n",
        "  max_feat=\"\";\n",
        "  # Comparitively find out which attribute gives us the maximum information\n",
        "  for attribute in attributes:\n",
        "    gain=info_gain(data_set,attribute)\n",
        "    if gain>max_gain:\n",
        "      max_gain=gain\n",
        "      max_feat=attribute\n",
        "  # once we find the max gain, that will be the attribute which we use.\n",
        "  root.value=max_feat\n",
        "\n",
        "  # All types of a particular attribute. Ex: In outlook, we have sunny,rain,overcast \n",
        "  types=np.unique(data_set[max_feat])\n",
        "\n",
        "  for t in types:\n",
        "    # Get all instances which match a particular type\n",
        "    subdata=data_set[data_set[max_feat]==t]\n",
        "\n",
        "    # In case we find instances where we have only one type of data result (yes/no). Entropy will be zero (Obviously!!)\n",
        "    if entropy(subdata)==0.0:\n",
        "      newNode=Node()\n",
        "      newNode.isLeaf=True\n",
        "      newNode.value=t\n",
        "      newNode.pred=np.unique(subdata[\"answer\"])\n",
        "      root.children.append(newNode)\n",
        "    else:\n",
        "      # If even one instance has different type of data result, we still cannot come to conclusion, \n",
        "      # hence go to the next attribute and create the node and apply the same algorithm on the next attribute.\n",
        "      dummyNode=Node()\n",
        "      dummyNode.value=t\n",
        "      new_attr=attributes.copy()\n",
        "      # We can remove the current attribute, only when we have come to a conclusion \n",
        "      # that we cannot decide with this attribute, we have gone to the next attribute. Hence we don't want to come back.\n",
        "      # + we may get stuck in cycle.\n",
        "      new_attr.remove(max_feat)\n",
        "\n",
        "      # Apply the algorithm on the next attribute with same current attributes which have been deleted.\n",
        "      child=ID3(subdata,new_attr)\n",
        "      dummyNode.children.append(child)\n",
        "      root.children.append(dummyNode)\n",
        "  return root\n",
        "\n",
        "\n",
        "def info_gain(data_set,feature):\n",
        "  types=np.unique(data_set[feature])\n",
        "  # We are trying to get the entropy for the entire data_set we have taken into consideration. \n",
        "  gain=entropy(data_set)\n",
        "\n",
        "  for u in types:\n",
        "    subdata=data_set[data_set[feature]==u]\n",
        "    sub_e=entropy(subdata)\n",
        "    gain-=(float(len(subdata))/float(len(data_set))*sub_e)\n",
        "\n",
        "  return gain\n",
        "\n",
        "def entropy(data):\n",
        "  pos=0\n",
        "  neg=0\n",
        "  # For the formula of entropy we need to see for how many of the +ve samples (yes) we have and how many -ve samples(no).\n",
        "  for _, row in data.iterrows():\n",
        "        if row['answer'] == \"yes\":\n",
        "            pos += 1\n",
        "        else:\n",
        "            neg += 1\n",
        "  if pos==0.0 or neg==0.0:\n",
        "    return 0.0\n",
        "  p=pos/(pos+neg)\n",
        "  n=neg/(pos+neg)\n",
        "  return -(p*math.log(p,2)+n*math.log(n,2))\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL3ptmXLGaqy",
        "outputId": "ece03c9e-9f80-412c-a8f8-bd8d6c80fec4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outlook\n",
            "\tovercast -> ['yes']\n",
            "\n",
            "\train\n",
            "\t\twind\n",
            "\t\t\tstrong -> ['no']\n",
            "\n",
            "\t\t\tweak -> ['yes']\n",
            "\n",
            "\tsunny\n",
            "\t\thumidity\n",
            "\t\t\thigh -> ['no']\n",
            "\n",
            "\t\t\tnormal -> ['yes']\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Welcome to Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}